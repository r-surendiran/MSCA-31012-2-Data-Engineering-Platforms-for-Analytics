{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import csv\n",
    "import string\n",
    "from tqdm import tqdm_notebook as tqdm\n",
    "import numpy as np\n",
    "import time\n",
    "import math\n",
    "\n",
    "\n",
    "def haversine(coord1, coord2):     # this is a function that calculates the distance between two GPS coordinates\n",
    "    R = 6372800  # Earth radius in meters\n",
    "    lat1, lon1 = coord1\n",
    "    lat2, lon2 = coord2\n",
    "    \n",
    "    phi1, phi2 = math.radians(lat1), math.radians(lat2) \n",
    "    dphi       = math.radians(lat2 - lat1)\n",
    "    dlambda    = math.radians(lon2 - lon1)\n",
    "    \n",
    "    a = math.sin(dphi/2)**2 + \\\n",
    "        math.cos(phi1)*math.cos(phi2)*math.sin(dlambda/2)**2\n",
    "    \n",
    "    return 2*R*math.atan2(math.sqrt(a), math.sqrt(1 - a))\n",
    "\n",
    "\n",
    "df_block_group = pd.read_csv('cbg_geographic_data.csv')    # This is the truncated file that only includes IL ZIP codes\n",
    "df_zipcodes = pd.read_csv('datasets_5391_8097_zip_lat_long.csv') # This is the truncated file that only includes GPS coordinates in or close to IL\n",
    "\n",
    "output = {}\n",
    "for index1, row1 in df_block_group.iterrows():\n",
    "    distance = 100000000 # very large number\n",
    "    zipcode = '000000'\n",
    "    for index2, row2 in df_zipcodes.iterrows():\n",
    "        if haversine( [row1['latitude'], row1['longitude']], [row2['LAT'], row2['LNG']]) < distance:\n",
    "            distance = haversine( [row1['latitude'], row1['longitude']], [row2['LAT'], row2['LNG']])\n",
    "            zipcode = row2['ZIP']\n",
    "    output[int(row1['census_block_group'])] = int(zipcode)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "w = csv.writer(open(\"CBG_zipcode.csv\", \"w\"))\n",
    "for key, val in output.items():\n",
    "    w.writerow([key, val])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# This snippet simply eliminates all non-Cook county ZIP codes from the CBG_zipcode.csv. Constant truncating of data\n",
    "# was necessary in order to reduce computation time.\n",
    "\n",
    "df_cbg_zipcode = pd.read_csv('CBG_zipcode.csv')\n",
    "\n",
    "df_Cook_zip = pd.read_csv('cook_zipcodes.csv')\n",
    "\n",
    "w = csv.writer(open(\"CBG_zipcode_2.csv\", \"w\"))\n",
    "for index1, row1 in df_cbg_zipcode.iterrows():\n",
    "    b = 0\n",
    "    for index2, row2 in df_Cook_zip.iterrows():\n",
    "        if row1['Zipcode'] == row2['Cook_zipcodes']:\n",
    "            b = 1\n",
    "    if b == 1:\n",
    "        w.writerow(row1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# code for getting data from SAFEGRAPH only for Cook county cbg's between dates Febr 01 - Apr 30\n",
    "\n",
    "# Note: This code was modified and run on the Midway cluster, as 90 different small scripts, each for a single date.\n",
    "# The 90 codes were run in parallel and then the resulting CSV's concatenated using the cat command in bash.\n",
    "\n",
    "# For this code to run, the social distancing data, which is downloaded as folders of gunzipped files corresponding to\n",
    "# each date, must be copied to a single folder and unzipped. The resulting file for Febr 01 2020, for example, has the \n",
    "# name 2020-02-01-social-distancing.csv.\n",
    "\n",
    "df_CBG_zipcode = pd.read_csv('CBG_zipcode_2.csv')\n",
    "\n",
    "date = '2020-{0}-{1}'\n",
    "\n",
    "date_cluster_0 = '2020-0{0}-0{1}'\n",
    "\n",
    "date_cluster = '2020-0{0}-{1}'\n",
    "\n",
    "days_in_month = [29,31,30]  \n",
    "\n",
    "w = csv.writer(\"Social_distancing_data_Cook_county.csv\")\n",
    "\n",
    "for i in range(2,5):\n",
    "    for j in range(1,days_in_month[i-2]+1):\n",
    "        if j > 9:\n",
    "            df_social_dist = pd.read_csv(date_cluster.format(i,j) + '-social-distancing.csv')\n",
    "        else:\n",
    "            df_social_dist = pd.read_csv(date_cluster_0.format(i,j) + '-social-distancing.csv')\n",
    "        output = []\n",
    "        for index1, row1 in df_social_dist.iterrows():\n",
    "            for index2, row2 in df_CBG_zipcode.iterrows():\n",
    "                if row1['origin_census_block_group'] == row2['CBG']:\n",
    "                    row_output = [row2['CBG'], row2['Zipcode'], date.format(i,j)]\n",
    "                    for column in df_social_dist.columns:\n",
    "                        if column != 'origin_census_block_group' and column != 'date_range_start' and column != 'date_range_end':\n",
    "                            row_output.append(row1[column])\n",
    "                    output.append(row_output)\n",
    "        for item in output:\n",
    "            w.writerow(item)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# This snippet of code aggregates the data per ZIP code. If the data is a MEDIAN, then it computes the MEDIAN of\n",
    "# all values across different CBG's. If the data is a count, it adds together the values across different CBG's. \n",
    "\n",
    "def read_list(line):\n",
    "    line = line.strip('[]').split(',')\n",
    "    return [int(x) for x in line]\n",
    "\n",
    "\n",
    "df_Cook_zip = pd.read_csv('cook_zipcodes.csv')\n",
    "df_social_dist = pd.read_csv('Social_distancing_data_Cook_county.csv')\n",
    "\n",
    "w = csv.writer(open(\"Social_distancing_data_Cook_febr_april.csv\", \"w\"))\n",
    "columns = ['zipcode', 'date', 'device_count', 'distance_traveled_from_home', 'completely_home_device_count', 'median_home_dwell_time', 'part_time_work_behavior_devices', 'full_time_work_behavior_devices', 'delivery_behavior_devices', 'median_non_home_dwell_time', 'candidate_device_count', 'median_percentage_time_home']\n",
    "\n",
    "    \n",
    "w.writerow(columns)\n",
    "\n",
    "date = '2020-{0}-{1}'\n",
    "days_in_month = [29,31,30]\n",
    "\n",
    "for index1, row1 in df_Cook_zip.iterrows():\n",
    "    for i in range(2,5):\n",
    "        for j in range(1,days_in_month[i-2]+1):\n",
    "            device_count = 0\n",
    "            distance_traveled_from_home = [] \n",
    "            completely_home_device_count = 0\n",
    "            median_home_dwell_time = [] \n",
    "            part_time_work_behavior_devices = 0 \n",
    "            full_time_work_behavior_devices = 0\n",
    "            delivery_behavior_devices = 0\n",
    "            median_non_home_dwell_time = [] \n",
    "            candidate_device_count = 0\n",
    "            median_percentage_time_home = [] \n",
    "            date_local = date.format(i,j)\n",
    "            for index2, row2 in df_social_dist.iterrows():\n",
    "                if row2['zipcode'] == row1['Cook_zipcodes'] and row2['date'] == date_local:\n",
    "                    device_count += row2['device_count']\n",
    "                    distance_traveled_from_home.append(row2['distance_traveled_from_home'])\n",
    "                    completely_home_device_count += row2['completely_home_device_count']\n",
    "                    median_home_dwell_time.append(row2['median_home_dwell_time']) \n",
    "                    part_time_work_behavior_devices += row2['part_time_work_behavior_devices'] \n",
    "                    full_time_work_behavior_devices += row2['full_time_work_behavior_devices']\n",
    "                    delivery_behavior_devices += row2['delivery_behavior_devices']\n",
    "                    median_non_home_dwell_time.append(row2['median_non_home_dwell_time'])  \n",
    "                    candidate_device_count += row2['candidate_device_count']\n",
    "                    median_percentage_time_home.append(row2['median_percentage_time_home'])  \n",
    "            distance_traveled_from_home = np.median(distance_traveled_from_home)\n",
    "            median_home_dwell_time = np.median(median_home_dwell_time)\n",
    "            median_non_home_dwell_time = np.median(median_non_home_dwell_time)\n",
    "            median_percentage_time_home = np.median(median_percentage_time_home)\n",
    "            output = [int(row1['Cook_zipcodes']), date_local, int(device_count), distance_traveled_from_home, int(completely_home_device_count), median_home_dwell_time, int(part_time_work_behavior_devices), int(full_time_work_behavior_devices), int(delivery_behavior_devices), median_non_home_dwell_time, int(candidate_device_count), median_percentage_time_home]\n",
    "            w.writerow(output)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
